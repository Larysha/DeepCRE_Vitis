#!/usr/bin/env Rscript
# Advanced feature filtering for genomic coordinate BLAMM results
# Applies quartile, weight region, and word size filtering with feature annotation
# Refactored from mo_feat-filter series for genomic coordinate workflow
######################

library(tidyr)
library(dplyr)
library(readr)
library(stringr)
library(magrittr)

# Source utility functions
source("../utils.R")

# Command line arguments with defaults
args <- commandArgs(trailingOnly = TRUE)

# Default file paths
default_input_file <- "../../../out/moca_results/mo_proj/filtering/filtered_genomic_occurrences.txt"
default_output_dir <- "../../../out/moca_results/mo_proj/filtering/"
default_tss_ranges <- "../../../out/moca_results/mo_range/vitisssr-TSS_motif_ranges_q1q9.csv"
default_tts_ranges <- "../../../out/moca_results/mo_range/vitisssr-TTS_motif_ranges_q1q9.csv"
default_annotation_file <- "../../../vitis_data/gene_models/vitis_vinifera_PN40024.gff3"

# Parse arguments
INPUT_FILE <- if (length(args) >= 1 && nzchar(args[1])) args[1] else default_input_file
OUTPUT_DIR <- if (length(args) >= 2 && nzchar(args[2])) args[2] else default_output_dir
TSS_RANGES <- if (length(args) >= 3 && nzchar(args[3])) args[3] else default_tss_ranges
TTS_RANGES <- if (length(args) >= 4 && nzchar(args[4])) args[4] else default_tts_ranges
ANNOTATION_FILE <- if (length(args) >= 5 && nzchar(args[5])) args[5] else default_annotation_file

# Filtering parameters
WEIGHT_REGION_FILTER <- TRUE  # Apply 20% minimum representation threshold (AND logic)
WORD_SIZE_FILTER <- 14       # Minimum motif length in bp
DATE_STAMP <- format(Sys.Date(), "%Y%m%d")

# CHROMOSOME EXCLUSIONS FOR CURRENT MODEL
# chr00: Extra chromosome - model never trains on this, ALWAYS exclude
EXCLUDED_CHROMOSOMES <- c("chr00")

# Create output directory if needed
if (!dir.exists(OUTPUT_DIR)) {
  dir.create(OUTPUT_DIR, recursive = TRUE, showWarnings = FALSE)
  cat("Created output directory:", OUTPUT_DIR, "\n")
}

cat("Genomic Feature Filtering Parameters:\n")
cat("  Input file:", INPUT_FILE, "\n")
cat("  Output directory:", OUTPUT_DIR, "\n")
cat("  TSS ranges:", TSS_RANGES, "\n")
cat("  TTS ranges:", TTS_RANGES, "\n")
cat("  Weight region filter:", WEIGHT_REGION_FILTER, "\n")
cat("  Word size filter:", WORD_SIZE_FILTER, "bp\n")
cat("  Excluded chromosomes:", paste(EXCLUDED_CHROMOSOMES, collapse = ", "), "\n")
cat("  Date stamp:", DATE_STAMP, "\n\n")

#' Convert motif names to EPM format for matching with seqlet statistics
#' 
#' This function standardizes motif names from BLAMM output to match the format
#' used in the motif range files from mo_range analysis. Critical for linking
#' motif occurrences with their positional preferences from model training.
#' 
#' @param code Character vector of motif names from BLAMM
#' @return Character vector of standardized EPM names
convert_epm_vitis <- function(code) {
  # Convert BLAMM format to seqlet statistics format
  # BLAMM: "epm_vitis_ssr_5_0_R_534" (pattern_metacluster_strand_count)
  # Target: "epm_vitis_ssr_p0m05" (p{metacluster}m{pattern_padded})
  
  # Split by underscore to get components
  parts <- strsplit(code, "_")
  
  converted <- sapply(parts, function(p) {
    if (length(p) >= 6) {
      # Extract pattern number (4th element) and metacluster (5th element)
      pattern_num <- as.numeric(p[4])
      metacluster <- as.numeric(p[5])
      
      # Format as p{metacluster}m{pattern_padded} to match seqlet statistics
      formatted_pattern <- sprintf("p%dm%02d", metacluster, pattern_num)
      
      # Reconstruct: epm_vitis_ssr_p{metacluster}m{pattern}
      paste("epm_vitis_ssr", formatted_pattern, sep = "_")
    } else {
      # Fallback for unexpected formats
      code
    }
  })
  
  return(converted)
}

#' Load and validate seqlet motif range data
#' 
#' Loads the TSS and TTS motif range files generated by mo_range analysis.
#' These contain quartile boundaries (Q10/Q90) and statistics for each motif's
#' positional preferences during model training.
#' 
#' @param tss_file Path to TSS motif ranges file
#' @param tts_file Path to TTS motif ranges file  
#' @return List containing tss_ranges and tts_ranges data frames
load_motif_ranges <- function(tss_file, tts_file) {
  
  cat("Loading motif range statistics...\n")
  
  # Load TSS ranges
  if (!file.exists(tss_file)) {
    stop("TSS ranges file not found: ", tss_file)
  }
  tss_ranges <- read.csv(tss_file, stringsAsFactors = FALSE)
  cat("  Loaded", nrow(tss_ranges), "TSS motif ranges\n")
  
  # Load TTS ranges  
  if (!file.exists(tts_file)) {
    stop("TTS ranges file not found: ", tts_file)
  }
  tts_ranges <- read.csv(tts_file, stringsAsFactors = FALSE)
  cat("  Loaded", nrow(tts_ranges), "TTS motif ranges\n")
  
  # Validate required columns
  required_cols <- c("epm", "min", "max", "q10", "q90", "number")
  
  if (!all(required_cols %in% colnames(tss_ranges))) {
    stop("Missing required columns in TSS ranges: ", 
         paste(setdiff(required_cols, colnames(tss_ranges)), collapse = ", "))
  }
  
  if (!all(required_cols %in% colnames(tts_ranges))) {
    stop("Missing required columns in TTS ranges: ", 
         paste(setdiff(required_cols, colnames(tts_ranges)), collapse = ", "))
  }
  
  return(list(tss = tss_ranges, tts = tts_ranges))
}

#' Apply advanced filtering pipeline to genomic motif occurrences
#' 
#' This function implements the complete feature filtering pipeline:
#' 1. Converts motif names to EPM format
#' 2. Adds upstream/downstream classification (legacy compatibility)
#' 3. Applies quartile filtering (Q10/Q90 boundaries)
#' 4. Applies weight region filtering (20% representation threshold)
#' 5. Applies word size filtering (minimum motif length)
#' 6. Adds feature annotations
#' 
#' @param input_file Path to genomic filtering output
#' @param motif_ranges List containing TSS and TTS range data
#' @param weight_filter Boolean to apply weight region filtering
#' @param word_size Integer minimum motif length
#' @return List containing filtered data frames for different output types
apply_feature_filtering <- function(input_file, motif_ranges, weight_filter, word_size) {
  
  cat("Loading genomic occurrence data...\n")
  
  # Load genomic filtering output
  if (!file.exists(input_file)) {
    stop("Input file not found: ", input_file)
  }
  
  motif_data <- read.table(input_file, header = TRUE, sep = "\t", stringsAsFactors = FALSE)
  cat("Loaded", nrow(motif_data), "motif occurrences\n")
  
  # STEP 1: Add EPM names for seqlet matching
  cat("\nStep 1: Converting motif names to EPM format...\n")
  motif_data$epm <- convert_epm_vitis(motif_data$motif)
  
  # Check how many motifs have matching seqlet data
  tss_epms <- unique(motif_ranges$tss$epm)
  tts_epms <- unique(motif_ranges$tts$epm)
  all_range_epms <- unique(c(tss_epms, tts_epms))
  
  matched_epms <- intersect(unique(motif_data$epm), all_range_epms)
  cat("  EPM matches: ", length(matched_epms), "/", length(unique(motif_data$epm)), 
      " unique motifs have seqlet statistics\n")
  
  # STEP 2: Add legacy upstream/downstream classification
  cat("\nStep 2: Adding upstream/downstream classification...\n")
  motif_data <- motif_data %>%
    mutate(
      # Calculate distance to gene start and end
      dist_to_start = abs(pos_relative_to_gene),
      dist_to_end = abs(pos_relative_to_gene - gene_length),
      
      # Classic upstream/downstream assignment (closest boundary)
      classic_region = case_when(
        pos_relative_to_gene <= 0 ~ "upstream",     # Before gene
        pos_relative_to_gene > gene_length ~ "downstream",  # After gene
        dist_to_start <= dist_to_end ~ "upstream",   # Closer to start
        TRUE ~ "downstream"                          # Closer to end
      ),
      
      # Apply strand correction (invert for negative strand genes)
      classic_region_corrected = case_when(
        gene_strand == "-" & classic_region == "upstream" ~ "downstream",
        gene_strand == "-" & classic_region == "downstream" ~ "upstream", 
        TRUE ~ classic_region
      ),
      
      # Calculate distance to transcription boundary for seqlet filtering
      dist_transc_border = pmin(dist_to_start, dist_to_end)
    )
  
  cat("  Classic region distribution:\n")
  classic_counts <- table(motif_data$classic_region_corrected)
  for (i in names(classic_counts)) {
    cat("    ", i, ":", classic_counts[i], "\n")
  }
  
  # STEP 3: Apply quartile filtering (Q10/Q90 boundaries)
  cat("\nStep 3: Applying quartile filtering (Q10/Q90)...\n")
  
  # Process upstream motifs with TSS ranges
  upstream_data <- motif_data %>%
    filter(classic_region_corrected == "upstream") %>%
    left_join(motif_ranges$tss %>% select(epm, min, max, q10, q90, number), 
              by = "epm") %>%
    filter(!is.na(q10)) %>%  # Keep only motifs with seqlet data
    filter(dist_transc_border >= q10 & dist_transc_border <= q90)
  
  # Process downstream motifs with TTS ranges
  downstream_data <- motif_data %>%
    filter(classic_region_corrected == "downstream") %>%
    left_join(motif_ranges$tts %>% select(epm, min, max, q10, q90, number), 
              by = "epm") %>%
    filter(!is.na(q10)) %>%  # Keep only motifs with seqlet data
    filter(dist_transc_border >= q10 & dist_transc_border <= q90)
  
  # Combine quartile-filtered data
  quartile_filtered <- rbind(upstream_data, downstream_data)
  
  cat("  Quartile filtering results:\n")
  cat("    Input occurrences:", nrow(motif_data), "\n")
  cat("    After quartile filter:", nrow(quartile_filtered), 
      "(", round(100 * nrow(quartile_filtered) / nrow(motif_data), 1), "%)\n")
  
  # STEP 4: Apply weight region filtering (20% representation threshold)
  weight_filtered <- quartile_filtered
  
  if (weight_filter) {
    cat("\nStep 4: Applying weight region filtering (20% threshold - AND logic)...\n")

    # Calculate weight regions to exclude using AND logic
    # Only exclude motifs that have <20% representation in BOTH regions
    weight_exclusions <- data.frame()

    # Check each motif's regional representation
    for (epm in unique(quartile_filtered$epm)) {
      # Get counts for this motif in TSS and TTS
      tss_count <- motif_ranges$tss %>% filter(epm == !!epm) %>% pull(number)
      tts_count <- motif_ranges$tts %>% filter(epm == !!epm) %>% pull(number)

      if (length(tss_count) > 0 && length(tts_count) > 0) {
        total_count <- tss_count + tts_count
        tss_percent <- tss_count / total_count
        tts_percent <- tts_count / total_count

        # AND logic: Only exclude if BOTH regions have <20% representation
        # This preserves specialized motifs that are >20% in at least one region
        if (tss_percent < 0.20 && tts_percent < 0.20) {
          # Exclude this motif from BOTH regions since it's under-represented everywhere
          weight_exclusions <- rbind(weight_exclusions,
                                   data.frame(epm = epm, region = "upstream"),
                                   data.frame(epm = epm, region = "downstream"))
        }
      }
    }
    
    # Apply weight filter exclusions
    if (nrow(weight_exclusions) > 0) {
      weight_filtered <- quartile_filtered %>%
        anti_join(weight_exclusions, by = c("epm", "classic_region_corrected" = "region"))
      
      cat("    Excluded", nrow(weight_exclusions), "epm-region combinations\n")
      cat("    After weight filter:", nrow(weight_filtered), 
          "(", round(100 * nrow(weight_filtered) / nrow(quartile_filtered), 1), "%)\n")
    } else {
      cat("    No motifs excluded by weight filter\n")
    }
  }
  
  # STEP 5: Apply word size filtering (minimum motif length)
  cat("\nStep 5: Applying word size filtering (", word_size, "bp minimum)...\n")
  
  final_filtered <- weight_filtered %>%
    mutate(motif_length = mend - mstart + 1) %>%
    filter(motif_length >= word_size)
  
  cat("  Word size filtering results:\n")
  cat("    Before word size filter:", nrow(weight_filtered), "\n")
  cat("    After word size filter:", nrow(final_filtered), 
      "(", round(100 * nrow(final_filtered) / nrow(weight_filtered), 1), "%)\n")
  
  # STEP 6: Add feature annotations
  cat("\nStep 6: Adding feature annotations...\n")
  
  final_annotated <- final_filtered %>%
    mutate(
      # Feature classification based on position
      feature_type = case_when(
        motif_region == "upstream_flank" ~ "promoter",
        motif_region == "downstream_flank" ~ "terminator", 
        motif_region == "five_prime_utr" ~ "5_prime_UTR",
        motif_region == "three_prime_utr" ~ "3_prime_UTR",
        TRUE ~ motif_region
      ),
      
      # Transcribed vs untranscribed classification
      transcription_status = case_when(
        motif_region %in% c("five_prime_utr", "three_prime_utr") ~ "transcribed",
        motif_region %in% c("upstream_flank", "downstream_flank") ~ "untranscribed",
        TRUE ~ "unknown"
      ),
      
      # Calculate genomic coordinates for motif
      motif_genomic_start = gene_start + pos_relative_to_gene - 1,
      motif_genomic_end = motif_genomic_start + motif_length - 1
    )
  
  # STEP 7: Create output datasets
  cat("\nStep 7: Preparing output datasets...\n")
  
  # Default dataset (all regions, basic filtering)
  default_output <- motif_data %>%
    mutate(
      motif_length = mend - mstart + 1,
      motif_genomic_start = gene_start + pos_relative_to_gene - 1,
      motif_genomic_end = motif_genomic_start + motif_length - 1
    ) %>%
    filter(motif_length >= word_size)
  
  # Q10/Q90 filtered dataset (quartile + weight + word size filters)
  q10q90_output <- final_annotated
  
  # Feature annotation dataset (detailed annotations for functional analysis)
  feature_output <- final_annotated %>%
    select(gene_id, motif, epm, chr, motif_genomic_start, motif_genomic_end,
           score, strand, gene_start, gene_end, gene_strand, motif_region,
           classic_region_corrected, feature_type, transcription_status,
           dist_transc_border, motif_length, q10, q90, min, max)
  
  # Summary statistics
  cat("\nFinal filtering summary:\n")
  cat("  Input occurrences:", nrow(motif_data), "\n")
  cat("  Default output (word size only):", nrow(default_output), "\n")
  cat("  Q10/Q90 filtered output:", nrow(q10q90_output), "\n")
  cat("  Feature annotation entries:", nrow(feature_output), "\n")
  
  return(list(
    default = default_output,
    q10q90 = q10q90_output, 
    features = feature_output,
    stats = list(
      input_count = nrow(motif_data),
      default_count = nrow(default_output),
      q10q90_count = nrow(q10q90_output),
      feature_count = nrow(feature_output)
    )
  ))
}

#' Generate BED files for genome browser visualization
#' 
#' Creates properly formatted BED files for visualizing motif locations
#' in genome browsers like IGV. Includes strand information and scores.
#' 
#' @param data_list List containing filtered datasets
#' @param output_dir Directory for output files
#' @param date_stamp Date stamp for file naming
create_bed_files <- function(data_list, output_dir, date_stamp) {
  
  cat("\nGenerating BED files for genome browser visualization...\n")
  
  # Function to create BED format
  create_bed_format <- function(data, name_suffix) {
    bed_data <- data %>%
      select(chr, motif_genomic_start, motif_genomic_end, motif, score, strand) %>%
      rename(
        chrom = chr,
        chromStart = motif_genomic_start,
        chromEnd = motif_genomic_end,
        name = motif,
        strand = strand
      ) %>%
      mutate(
        # BED format requirements
        thickStart = chromStart,
        thickEnd = chromEnd,
        itemRgb = "255,0,127"  # Pink color for motifs
      )
    
    # Write BED file
    bed_file <- file.path(output_dir, paste0(date_stamp, "_vitis_motifs_", name_suffix, ".bed"))
    write.table(bed_data, bed_file, sep = "\t", row.names = FALSE, 
                col.names = FALSE, quote = FALSE)
    
    cat("  Created BED file:", basename(bed_file), "(", nrow(bed_data), "entries )\n")
    return(bed_file)
  }
  
  # Create BED files for each dataset
  bed_files <- list()
  bed_files$default <- create_bed_format(data_list$default, "default")
  bed_files$q10q90 <- create_bed_format(data_list$q10q90, "q10q90_filtered")
  
  return(bed_files)
}

# Main execution
cat("Starting genomic feature filtering pipeline...\n")

# Load motif range statistics
motif_ranges <- load_motif_ranges(TSS_RANGES, TTS_RANGES)

# Apply filtering pipeline
filtered_results <- apply_feature_filtering(INPUT_FILE, motif_ranges, 
                                          WEIGHT_REGION_FILTER, WORD_SIZE_FILTER)

# Generate output files
output_base <- file.path(OUTPUT_DIR, paste0(DATE_STAMP, "_vitis_ssr"))

cat("\nWriting output files...\n")

# CSV outputs
write.csv(filtered_results$default, 
          paste0(output_base, "_default.csv"), row.names = FALSE)
cat("  Default CSV:", basename(paste0(output_base, "_default.csv")), "\n")

write.csv(filtered_results$q10q90, 
          paste0(output_base, "_q10q90_filtered.csv"), row.names = FALSE)
cat("  Q10/Q90 filtered CSV:", basename(paste0(output_base, "_q10q90_filtered.csv")), "\n")

write.csv(filtered_results$features, 
          paste0(output_base, "_feature_annotations.csv"), row.names = FALSE)
cat("  Feature annotations CSV:", basename(paste0(output_base, "_feature_annotations.csv")), "\n")

# BED files
bed_files <- create_bed_files(filtered_results, OUTPUT_DIR, DATE_STAMP)

# Summary report
cat("\n" , rep("=", 60), "\n", sep = "")
cat("GENOMIC FEATURE FILTERING COMPLETED\n")
cat(rep("=", 60), "\n\n", sep = "")

cat("Filtering Statistics:\n")
cat("  Total input occurrences (excluding chr00):", filtered_results$stats$input_count, "\n")
cat("  Default output (word size filter):", filtered_results$stats$default_count, 
    sprintf(" (%.1f%%)", 100 * filtered_results$stats$default_count / filtered_results$stats$input_count), "\n")
cat("  Q10/Q90 filtered:", filtered_results$stats$q10q90_count,
    sprintf(" (%.1f%%)", 100 * filtered_results$stats$q10q90_count / filtered_results$stats$input_count), "\n")
cat("  NOTE: chr00 (always excluded) filtered out\n")

cat("\nOutput Files Created:\n")
cat("  CSV files: 3\n")
cat("  BED files: 2\n")
cat("  Output directory:", OUTPUT_DIR, "\n")

cat("\nNext Steps:\n")
cat("  1. Load BED files in IGV for genome browser visualization\n")
cat("  2. Use feature_annotations.csv for GO enrichment analysis\n")
cat("  3. Use q10q90_filtered.csv for high-confidence motif analysis\n")
cat("  4. Compare motif distributions across genomic regions\n")

# Print session info for reproducibility
cat("\nSession Information:\n")
cat("R version:", R.version.string, "\n")
cat("Script completed at:", format(Sys.time(), "%Y-%m-%d %H:%M:%S"), "\n")